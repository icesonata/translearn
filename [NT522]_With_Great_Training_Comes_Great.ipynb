{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAAjP4PtamFM"
      },
      "source": [
        "Paper: http://people.cs.uchicago.edu/~ravenben/publications/pdf/translearn-usenixsec18.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJOBPZ7cCeCM",
        "outputId": "b5069633-cb3e-4691-a3ac-a8ffacd92624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'translearn'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Total 84 (delta 0), reused 0 (delta 0), pack-reused 84\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n",
            "/content/translearn\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bolunwang/translearn.git\n",
        "%cd translearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thabaz_29_Cv",
        "outputId": "a92643c7-a10f-4afb-830b-c86fa0373ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 792 kB 20.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 374 kB 51.9 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.24 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.31.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q ipdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLr-ZGttpIt5"
      },
      "source": [
        "# Inspect dataset in HDF5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rl-oUc3dpSz2"
      },
      "outputs": [],
      "source": [
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fNnBvXEspVwR"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"datasets/pubfig65_imagenet_test.h5\"\n",
        "f = h5py.File(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWht0AxfRuhk",
        "outputId": "273e0124-47dd-4da6-b645-17ea39eb13ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type: <class 'numpy.ndarray'>\n",
            "Shape: (65, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type:\", type(f.get(\"X_test\")[:]))\n",
        "print(\"Shape:\", f.get(\"X_test\").shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UofAHwqUVbf",
        "outputId": "d48c88a7-2f1e-478a-8898-9fd40037dee6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# lb = f.get(\"Y_test\")[:]\n",
        "f.get(\"Y_test\")[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV68kPFpURp-"
      },
      "source": [
        "## Convert numpy array to image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxexApPzhDXx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Ug052GjGNG"
      },
      "source": [
        "Convert numpy pixel array to image\n",
        "- https://stackoverflow.com/a/10967471\n",
        "- https://stackoverflow.com/a/2659378"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmjKD5eZhH5f"
      },
      "outputs": [],
      "source": [
        "sample_test_images = f.get(\"X_test\")[:]\n",
        "for num, image_array in enumerate(sample_test_images):\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(f\"sample_imagenet_test_{num}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCAFj0iurO1Y",
        "outputId": "92ffa242-94e9-4e66-f345-4be346226a9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sample_test_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNei3BhLohIc"
      },
      "source": [
        "## Test loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vdWlJGr8zYvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2093ab82-7fc8-4bad-f909-4fe9b06406d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        }
      ],
      "source": [
        "from pubfig65_vggface_mimic_penalty_dssim import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxV1VmGpznXo",
        "outputId": "7b596dfb-c093-4f62-a418-7c27e7a0a359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading student model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "loading teacher model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "building bottleneck model\n"
          ]
        }
      ],
      "source": [
        "(bottleneck_model, student_model) = load_and_build_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "C377dvpaoyVh"
      },
      "outputs": [],
      "source": [
        "X, Y = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkJhS08RVSh9",
        "outputId": "d5ca4ea8-e2ba-4801-9969-0fa9ff805510"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (65, 224, 224, 3)\n",
            "Y shape: (65,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.get(\"Y_test\")[0]"
      ],
      "metadata": {
        "id": "SI4XuNe_VW04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pubfig65_vggface_mimic_penalty_dssim import *"
      ],
      "metadata": {
        "id": "l8qrn3Yiyzwq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = utils_translearn.load_dataset(\n",
        "    DATA_FILE,\n",
        "    keys=['X_test', 'Y_test'])"
      ],
      "metadata": {
        "id": "QWhiQO9Xyw9n"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset['X_test']\n",
        "Y = dataset['Y_test']\n",
        "\n",
        "X = X.astype(np.float32)\n",
        "Y = Y.astype(np.float32)"
      ],
      "metadata": {
        "id": "yWzY0XkqzBof"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = utils_translearn.preprocess(X, INTENSITY_RANGE)\n",
        "Y = np.argmax(Y, axis=1)"
      ],
      "metadata": {
        "id": "t8TpUxsXzDLU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "\n",
        "image_array = X[0]\n",
        "im = Image.fromarray(np.uint8(image_array))\n",
        "im.save(f\"sample_imagenet_test_2.png\")"
      ],
      "metadata": {
        "id": "acJyynjBzWeR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_slUZv9zNX1",
        "outputId": "c6c218a8-9aba-4cee-e005-23c548422a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filtering data\n",
            "baseline accuracy of student 0.938462\n",
            "X shape: (61, 224, 224, 3)\n",
            "Y shape: (61,)\n"
          ]
        }
      ],
      "source": [
        "# filter data points, keep only correctly predicted samples\n",
        "print('filtering data')\n",
        "X, Y = filter_data(X, Y, student_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd9JguWhzyc7"
      },
      "outputs": [],
      "source": [
        "Y_label = list(np.unique(Y))\n",
        "all_pair_list = list(itertools.permutations(Y_label, 2))\n",
        "pair_list = random.sample(\n",
        "    all_pair_list,\n",
        "    min(NB_PAIR, len(all_pair_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s0L9Ei01qAU",
        "outputId": "eb77e0a4-c429-4480-cfa3-56f0ec8ffc03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(2, 21), (6, 40)]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pair_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3HHQ9X411kO"
      },
      "outputs": [],
      "source": [
        "(source, target) = pair_list[0]\n",
        "# sample images\n",
        "(X_source, Y_source, X_target, Y_target) = select_source_target(\n",
        "  X, Y, source, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifHNaf4K1-qF",
        "outputId": "9bb94cb5-b3e3-46eb-c7b4-0dc7c75ff12d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG51kYPm9wS0"
      },
      "outputs": [],
      "source": [
        "def load_and_build_models(student_model_file=STUDENT_MODEL_FILE,\n",
        "                          teacher_model_file=TEACHER_MODEL_FILE,\n",
        "                          cutoff_layer=CUTOFF_LAYER):\n",
        "\n",
        "    # load the student model\n",
        "    print('loading student model')\n",
        "    student_model = load_model(student_model_file)\n",
        "\n",
        "    print('loading teacher model')\n",
        "    teacher_model = load_model(teacher_model_file)\n",
        "\n",
        "    # load the bottleneck model\n",
        "    print('building bottleneck model')\n",
        "    import ipdb; ipdb.set_trace()\n",
        "    bottleneck_model = Model(teacher_model.input,\n",
        "                             teacher_model.layers[cutoff_layer - 1].output)\n",
        "    bottleneck_model.compile(loss='categorical_crossentropy',\n",
        "                             optimizer='adam',\n",
        "                             metrics=['accuracy'])\n",
        "\n",
        "    return bottleneck_model, student_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vEa7NvOb9zvV",
        "outputId": "1ac0186e-58b9-4189-b68a-6ef9cd4a7870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading student model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "loading teacher model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 332, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building bottleneck model\n",
            "> \u001b[0;32m<ipython-input-67-fecc055b9e2c>\u001b[0m(15)\u001b[0;36mload_and_build_models\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     14 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m    bottleneck_model = Model(teacher_model.input,\n",
            "\u001b[0m\u001b[0;32m     16 \u001b[0;31m                             teacher_model.layers[cutoff_layer - 1].output)\n",
            "\u001b[0m\n",
            "ipdb> teacher_model\n",
            "<keras.engine.functional.Functional object at 0x7f3a6a308590>\n",
            "ipdb> teacher_model.layers\n",
            "[<keras.engine.input_layer.InputLayer object at 0x7f3a6a30e910>, <keras.layers.convolutional.Conv2D object at 0x7f3ad9183750>, <keras.layers.core.activation.Activation object at 0x7f3a64c86790>, <keras.layers.convolutional.Conv2D object at 0x7f3ad91b3f10>, <keras.layers.core.activation.Activation object at 0x7f3a64c86410>, <keras.layers.pooling.MaxPooling2D object at 0x7f3a64df1790>, <keras.layers.convolutional.Conv2D object at 0x7f3a6a30e8d0>, <keras.layers.core.activation.Activation object at 0x7f3a64d9d890>, <keras.layers.convolutional.Conv2D object at 0x7f3a64d9df10>, <keras.layers.core.activation.Activation object at 0x7f3a64d9d8d0>, <keras.layers.pooling.MaxPooling2D object at 0x7f3a686a3e10>, <keras.layers.convolutional.Conv2D object at 0x7f3a687ecc90>, <keras.layers.core.activation.Activation object at 0x7f3ad9190f10>, <keras.layers.convolutional.Conv2D object at 0x7f3a64dd9450>, <keras.layers.core.activation.Activation object at 0x7f3a64ece150>, <keras.layers.convolutional.Conv2D object at 0x7f3a687f6a50>, <keras.layers.core.activation.Activation object at 0x7f3a64def090>, <keras.layers.pooling.MaxPooling2D object at 0x7f3a64dfaed0>, <keras.layers.convolutional.Conv2D object at 0x7f3a64def1d0>, <keras.layers.core.activation.Activation object at 0x7f3a64da38d0>, <keras.layers.convolutional.Conv2D object at 0x7f3a64eba090>, <keras.layers.core.activation.Activation object at 0x7f3a64c2bfd0>, <keras.layers.convolutional.Conv2D object at 0x7f3a64e6be50>, <keras.layers.core.activation.Activation object at 0x7f3a64c26690>, <keras.layers.pooling.MaxPooling2D object at 0x7f3a64c26f90>, <keras.layers.convolutional.Conv2D object at 0x7f3a64da2e10>, <keras.layers.core.activation.Activation object at 0x7f3a64c72290>, <keras.layers.convolutional.Conv2D object at 0x7f3a64bd1090>, <keras.layers.core.activation.Activation object at 0x7f3a63460710>, <keras.layers.convolutional.Conv2D object at 0x7f3a64bcc3d0>, <keras.layers.core.activation.Activation object at 0x7f3a64c35290>, <keras.layers.pooling.MaxPooling2D object at 0x7f3a64ba9b10>, <keras.layers.core.flatten.Flatten object at 0x7f3a64ba91d0>, <keras.layers.core.dense.Dense object at 0x7f3a64ca5750>, <keras.layers.core.activation.Activation object at 0x7f3a64ba4b90>, <keras.layers.core.dropout.Dropout object at 0x7f3a64ba4d90>, <keras.layers.core.dense.Dense object at 0x7f3a64ba2d50>, <keras.layers.core.activation.Activation object at 0x7f3a64c9a850>, <keras.layers.core.dropout.Dropout object at 0x7f3a64c9a610>, <keras.layers.core.dense.Dense object at 0x7f3a64c9ac90>, <keras.layers.core.activation.Activation object at 0x7f3a64bc6e10>]\n",
            "ipdb> teacher_model.layers.shape\n",
            "*** AttributeError: 'list' object has no attribute 'shape'\n",
            "ipdb> len(teacher_model.layers)\n",
            "41\n",
            "ipdb> from pprint import pprint\n",
            "ipdb> pprint(teacher_model.layers)\n",
            "[<keras.engine.input_layer.InputLayer object at 0x7f3a6a30e910>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3ad9183750>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c86790>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3ad91b3f10>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c86410>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64df1790>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a6a30e8d0>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64d9d890>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64d9df10>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64d9d8d0>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a686a3e10>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a687ecc90>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3ad9190f10>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64dd9450>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64ece150>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a687f6a50>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64def090>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64dfaed0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64def1d0>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64da38d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64eba090>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c2bfd0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64e6be50>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c26690>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64c26f90>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64da2e10>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c72290>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64bd1090>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a63460710>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64bcc3d0>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c35290>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64ba9b10>,\n",
            " <keras.layers.core.flatten.Flatten object at 0x7f3a64ba91d0>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a64ca5750>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64ba4b90>,\n",
            " <keras.layers.core.dropout.Dropout object at 0x7f3a64ba4d90>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a64ba2d50>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64c9a850>,\n",
            " <keras.layers.core.dropout.Dropout object at 0x7f3a64c9a610>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a64c9ac90>,\n",
            " <keras.layers.core.activation.Activation object at 0x7f3a64bc6e10>]\n",
            "ipdb> teacher_model.layers[cutoff_layer - 1]\n",
            "<keras.layers.core.activation.Activation object at 0x7f3a64c9a850>\n",
            "ipdb> teacher_model.layers[cutoff_layer - 1].output\n",
            "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'activation_15')>\n",
            "ipdb> teacher_model.layers[-1].output\n",
            "<KerasTensor: shape=(None, 2622) dtype=float32 (created by layer 'activation_16')>\n",
            "ipdb> teacher_model.layers[-2].output\n",
            "<KerasTensor: shape=(None, 2622) dtype=float32 (created by layer 'fc8')>\n",
            "ipdb> teacher_model.layers[-3].output\n",
            "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'dropout_2')>\n",
            "ipdb> teacher_model.layers[-4].output\n",
            "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'activation_15')>\n",
            "ipdb> teacher_model.layers[-5].output\n",
            "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'fc7')>\n",
            "ipdb> teacher_model.layers[-6].output\n",
            "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'dropout_1')>\n",
            "ipdb> teacher_model.layers[-7].output\n",
            "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'activation_14')>\n",
            "ipdb> for layer in teacher_model.layers[-1]: print(layer.output)\n",
            "*** TypeError: 'Activation' object is not iterable\n",
            "ipdb> for layer in teacher_model.layers: print(layer.output)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 64), dtype=tf.float32, name=None), name='conv1_1/BiasAdd:0', description=\"created by layer 'conv1_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 64), dtype=tf.float32, name=None), name='activation_1/Relu:0', description=\"created by layer 'activation_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 64), dtype=tf.float32, name=None), name='conv1_2/BiasAdd:0', description=\"created by layer 'conv1_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 64), dtype=tf.float32, name=None), name='activation_2/Relu:0', description=\"created by layer 'activation_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 112, 112, 64), dtype=tf.float32, name=None), name='pool1/MaxPool:0', description=\"created by layer 'pool1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 112, 112, 128), dtype=tf.float32, name=None), name='conv2_1/BiasAdd:0', description=\"created by layer 'conv2_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 112, 112, 128), dtype=tf.float32, name=None), name='activation_3/Relu:0', description=\"created by layer 'activation_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 112, 112, 128), dtype=tf.float32, name=None), name='conv2_2/BiasAdd:0', description=\"created by layer 'conv2_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 112, 112, 128), dtype=tf.float32, name=None), name='activation_4/Relu:0', description=\"created by layer 'activation_4'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 128), dtype=tf.float32, name=None), name='pool2/MaxPool:0', description=\"created by layer 'pool2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 256), dtype=tf.float32, name=None), name='conv3_1/BiasAdd:0', description=\"created by layer 'conv3_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 256), dtype=tf.float32, name=None), name='activation_5/Relu:0', description=\"created by layer 'activation_5'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 256), dtype=tf.float32, name=None), name='conv3_2/BiasAdd:0', description=\"created by layer 'conv3_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 256), dtype=tf.float32, name=None), name='activation_6/Relu:0', description=\"created by layer 'activation_6'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 256), dtype=tf.float32, name=None), name='conv3_3/BiasAdd:0', description=\"created by layer 'conv3_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 256), dtype=tf.float32, name=None), name='activation_7/Relu:0', description=\"created by layer 'activation_7'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 256), dtype=tf.float32, name=None), name='pool3/MaxPool:0', description=\"created by layer 'pool3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 512), dtype=tf.float32, name=None), name='conv4_1/BiasAdd:0', description=\"created by layer 'conv4_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 512), dtype=tf.float32, name=None), name='activation_8/Relu:0', description=\"created by layer 'activation_8'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 512), dtype=tf.float32, name=None), name='conv4_2/BiasAdd:0', description=\"created by layer 'conv4_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 512), dtype=tf.float32, name=None), name='activation_9/Relu:0', description=\"created by layer 'activation_9'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 512), dtype=tf.float32, name=None), name='conv4_3/BiasAdd:0', description=\"created by layer 'conv4_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 512), dtype=tf.float32, name=None), name='activation_10/Relu:0', description=\"created by layer 'activation_10'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='pool4/MaxPool:0', description=\"created by layer 'pool4'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='conv5_1/BiasAdd:0', description=\"created by layer 'conv5_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='activation_11/Relu:0', description=\"created by layer 'activation_11'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='conv5_2/BiasAdd:0', description=\"created by layer 'conv5_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='activation_12/Relu:0', description=\"created by layer 'activation_12'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='conv5_3/BiasAdd:0', description=\"created by layer 'conv5_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 512), dtype=tf.float32, name=None), name='activation_13/Relu:0', description=\"created by layer 'activation_13'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='pool5/MaxPool:0', description=\"created by layer 'pool5'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 25088), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='fc6/BiasAdd:0', description=\"created by layer 'fc6'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='activation_14/Relu:0', description=\"created by layer 'activation_14'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='dropout_1/Identity:0', description=\"created by layer 'dropout_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='fc7/BiasAdd:0', description=\"created by layer 'fc7'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='activation_15/Relu:0', description=\"created by layer 'activation_15'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='dropout_2/Identity:0', description=\"created by layer 'dropout_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 2622), dtype=tf.float32, name=None), name='fc8/BiasAdd:0', description=\"created by layer 'fc8'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 2622), dtype=tf.float32, name=None), name='activation_16/Softmax:0', description=\"created by layer 'activation_16'\")\n",
            "ipdb> exit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 357, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "ename": "BdbQuit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-2c32ea16eb7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mbottleneck_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_build_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-fecc055b9e2c>\u001b[0m in \u001b[0;36mload_and_build_models\u001b[0;34m(student_model_file, teacher_model_file, cutoff_layer)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'building bottleneck model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     bottleneck_model = Model(teacher_model.input,\n\u001b[0m\u001b[1;32m     16\u001b[0m                              teacher_model.layers[cutoff_layer - 1].output)\n\u001b[1;32m     17\u001b[0m     bottleneck_model.compile(loss='categorical_crossentropy',\n",
            "\u001b[0;32m<ipython-input-67-fecc055b9e2c>\u001b[0m in \u001b[0;36mload_and_build_models\u001b[0;34m(student_model_file, teacher_model_file, cutoff_layer)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'building bottleneck model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     bottleneck_model = Model(teacher_model.input,\n\u001b[0m\u001b[1;32m     16\u001b[0m                              teacher_model.layers[cutoff_layer - 1].output)\n\u001b[1;32m     17\u001b[0m     bottleneck_model.compile(loss='categorical_crossentropy',\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ],
      "source": [
        "(bottleneck_model, student_model) = load_and_build_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-223PvDCHqi"
      },
      "source": [
        "# Prepare to run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8kuDMGnCKmo"
      },
      "source": [
        "Download exported model:\n",
        "- vggface.h5\n",
        "- pubfig65_vggface_trans_nbtrain_90.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zHcD92RW_ePb"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QmW0qQaTwuT",
        "outputId": "1dfd0600-895c-48f5-a645-eb2692c3e348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f2wV9nOLVKFM6JmeiCm3n05BmWZIQHyl\n",
            "To: /content/translearn/models/pubfig65_vggface_trans_nbtrain_90.h5\n",
            "100% 538M/538M [00:05<00:00, 90.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hQ-cVn1hy85rXSmgKFa-H0aIMUsVr1Tz\n",
            "To: /content/translearn/models/vggface.h5\n",
            "100% 580M/580M [00:04<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./models\n",
        "!gdown \"https://drive.google.com/uc?id=1f2wV9nOLVKFM6JmeiCm3n05BmWZIQHyl\" -O \"models/pubfig65_vggface_trans_nbtrain_90.h5\"\n",
        "!gdown \"https://drive.google.com/uc?id=1hQ-cVn1hy85rXSmgKFa-H0aIMUsVr1Tz\" -O \"models/vggface.h5\"\n",
        "# !cp datasets/pubfig65_imagenet_test.h5 models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4G3mXPTIwOz",
        "outputId": "8f5c68fb-c5c3-468d-b8b4-3363313545e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.7.0\n",
            "Cuda Version: 11.1\n",
            "Cudnn version: 8\n"
          ]
        }
      ],
      "source": [
        "# Check CUDA version\n",
        "# https://stackoverflow.com/questions/9727688/how-to-get-the-cuda-version\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.platform import build_info as build\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "print(f\"Cuda Version: {build.build_info['cuda_version']}\")\n",
        "print(f\"Cudnn version: {build.build_info['cudnn_version']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYmFFE0QNn3n",
        "outputId": "c77ac055-2624-4fd6-9843-4f91f9b1b598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-01-03 04:08:12--  https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://developer.nvidia.com/compute/cuda/9.0/prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb [following]\n",
            "--2022-01-03 04:08:12--  https://developer.nvidia.com/compute/cuda/9.0/prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\n",
            "Reusing existing connection to developer.nvidia.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64.deb?TMV1g2WVlpv_Jrxec4h44te6sKcgb8MIDzKXM_7speDL07Bg5CfH-jsyLVQW9_P3gSeNaOl1KWX2-1SFcKdXNvQOKk_zNMd1RCl5_ouuKQv1tAoSdrHoNR0r_SWmfwqwkm2zpJOA350xvE8ZDBa-Wnf2Ew7h6sI7dh9QteH6ldQynUQcKVffyNhvqpEvsQq2eNncL1DlMwATK4eRj-tx [following]\n",
            "--2022-01-03 04:08:13--  https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64.deb?TMV1g2WVlpv_Jrxec4h44te6sKcgb8MIDzKXM_7speDL07Bg5CfH-jsyLVQW9_P3gSeNaOl1KWX2-1SFcKdXNvQOKk_zNMd1RCl5_ouuKQv1tAoSdrHoNR0r_SWmfwqwkm2zpJOA350xvE8ZDBa-Wnf2Ew7h6sI7dh9QteH6ldQynUQcKVffyNhvqpEvsQq2eNncL1DlMwATK4eRj-tx\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1216133170 (1.1G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb’\n",
            "\n",
            "cuda-repo-ubuntu170 100%[===================>]   1.13G  29.5MB/s    in 22s     \n",
            "\n",
            "2022-01-03 04:08:35 (53.4 MB/s) - ‘cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb’ saved [1216133170/1216133170]\n",
            "\n",
            "cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\n",
            "datasets\n",
            "LICENSE\n",
            "mimic_penalty_dssim.py\n",
            "models\n",
            "msssim_tf.py\n",
            "pubfig65_fingerprint_vgg16.py\n",
            "pubfig65_fingerprint_vggface.py\n",
            "pubfig65_patch_neuron_distance.py\n",
            "pubfig65_vggface_mimic_penalty_dssim.py\n",
            "README.md\n",
            "utils_translearn.py\n",
            "Selecting previously unselected package cuda-repo-ubuntu1704-9-0-local.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1704-9-0-local (9.0.176-1) ...\n",
            "Setting up cuda-repo-ubuntu1704-9-0-local (9.0.176-1) ...\n",
            "7fa2af80.pub\n",
            "OK\n",
            "Get:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:7 file:/var/cuda-repo-9-0-local  Packages [15.8 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.9 kB]\n",
            "Hit:16 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [833 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,822 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,452 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,230 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n",
            "Get:27 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.6 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.6 kB]\n",
            "Get:31 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:32 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.7 kB]\n",
            "Fetched 13.8 MB in 4s (3,792 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'cuda-9-0' for regex 'cuda-9.0'\n",
            "Note, selecting 'libcuda-9.0-1' for regex 'cuda-9.0'\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "The following NEW packages will be installed:\n",
            "  cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "0 upgraded, 33 newly installed, 0 to remove and 100 not upgraded.\n",
            "Need to get 0 B/1,097 MB of archives.\n",
            "After this operation, 2,315 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-9-0-local  cuda-license-9-0 9.0.176-1 [22.0 kB]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  cuda-misc-headers-9-0 9.0.176-1 [684 kB]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  cuda-core-9-0 9.0.176-1 [16.9 MB]\n",
            "Get:4 file:/var/cuda-repo-9-0-local  cuda-cudart-9-0 9.0.176-1 [106 kB]\n",
            "Get:5 file:/var/cuda-repo-9-0-local  cuda-driver-dev-9-0 9.0.176-1 [10.9 kB]\n",
            "Get:6 file:/var/cuda-repo-9-0-local  cuda-cudart-dev-9-0 9.0.176-1 [767 kB]\n",
            "Get:7 file:/var/cuda-repo-9-0-local  cuda-command-line-tools-9-0 9.0.176-1 [25.4 MB]\n",
            "Get:8 file:/var/cuda-repo-9-0-local  cuda-nvrtc-9-0 9.0.176-1 [6,348 kB]\n",
            "Get:9 file:/var/cuda-repo-9-0-local  cuda-nvrtc-dev-9-0 9.0.176-1 [9,334 B]\n",
            "Get:10 file:/var/cuda-repo-9-0-local  cuda-cusolver-9-0 9.0.176-1 [26.2 MB]\n",
            "Get:11 file:/var/cuda-repo-9-0-local  cuda-cusolver-dev-9-0 9.0.176-1 [5,317 kB]\n",
            "Get:12 file:/var/cuda-repo-9-0-local  cuda-cublas-9-0 9.0.176-1 [25.0 MB]\n",
            "Get:13 file:/var/cuda-repo-9-0-local  cuda-cublas-dev-9-0 9.0.176-1 [49.4 MB]\n",
            "Get:14 file:/var/cuda-repo-9-0-local  cuda-cufft-9-0 9.0.176-1 [84.1 MB]\n",
            "Get:15 file:/var/cuda-repo-9-0-local  cuda-cufft-dev-9-0 9.0.176-1 [73.7 MB]\n",
            "Get:16 file:/var/cuda-repo-9-0-local  cuda-curand-9-0 9.0.176-1 [38.8 MB]\n",
            "Get:17 file:/var/cuda-repo-9-0-local  cuda-curand-dev-9-0 9.0.176-1 [57.9 MB]\n",
            "Get:18 file:/var/cuda-repo-9-0-local  cuda-cusparse-9-0 9.0.176-1 [25.2 MB]\n",
            "Get:19 file:/var/cuda-repo-9-0-local  cuda-cusparse-dev-9-0 9.0.176-1 [25.3 MB]\n",
            "Get:20 file:/var/cuda-repo-9-0-local  cuda-npp-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:21 file:/var/cuda-repo-9-0-local  cuda-npp-dev-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:22 file:/var/cuda-repo-9-0-local  cuda-nvgraph-9-0 9.0.176-1 [6,081 kB]\n",
            "Get:23 file:/var/cuda-repo-9-0-local  cuda-nvgraph-dev-9-0 9.0.176-1 [5,658 kB]\n",
            "Get:24 file:/var/cuda-repo-9-0-local  cuda-samples-9-0 9.0.176-1 [75.9 MB]\n",
            "Get:25 file:/var/cuda-repo-9-0-local  cuda-documentation-9-0 9.0.176-1 [53.1 MB]\n",
            "Get:26 file:/var/cuda-repo-9-0-local  cuda-libraries-dev-9-0 9.0.176-1 [2,596 B]\n",
            "Get:27 file:/var/cuda-repo-9-0-local  cuda-nvml-dev-9-0 9.0.176-1 [47.6 kB]\n",
            "Get:28 file:/var/cuda-repo-9-0-local  cuda-visual-tools-9-0 9.0.176-1 [398 MB]\n",
            "Get:29 file:/var/cuda-repo-9-0-local  cuda-toolkit-9-0 9.0.176-1 [2,836 B]\n",
            "Get:30 file:/var/cuda-repo-9-0-local  cuda-libraries-9-0 9.0.176-1 [2,566 B]\n",
            "Get:31 file:/var/cuda-repo-9-0-local  cuda-runtime-9-0 9.0.176-1 [2,526 B]\n",
            "Get:32 file:/var/cuda-repo-9-0-local  cuda-demo-suite-9-0 9.0.176-1 [3,880 kB]\n",
            "Get:33 file:/var/cuda-repo-9-0-local  cuda-9-0 9.0.176-1 [2,552 B]\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 33.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cuda-license-9-0.\n",
            "(Reading database ... 155281 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-license-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-9-0.\n",
            "Preparing to unpack .../01-cuda-misc-headers-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-core-9-0.\n",
            "Preparing to unpack .../02-cuda-core-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-core-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-9-0.\n",
            "Preparing to unpack .../03-cuda-cudart-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-9-0.\n",
            "Preparing to unpack .../04-cuda-driver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-9-0.\n",
            "Preparing to unpack .../05-cuda-cudart-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-9-0.\n",
            "Preparing to unpack .../06-cuda-command-line-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-9-0.\n",
            "Preparing to unpack .../07-cuda-nvrtc-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-0.\n",
            "Preparing to unpack .../08-cuda-nvrtc-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-9-0.\n",
            "Preparing to unpack .../09-cuda-cusolver-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-0.\n",
            "Preparing to unpack .../10-cuda-cusolver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-9-0.\n",
            "Preparing to unpack .../11-cuda-cublas-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-dev-9-0.\n",
            "Preparing to unpack .../12-cuda-cublas-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-9-0.\n",
            "Preparing to unpack .../13-cuda-cufft-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-0.\n",
            "Preparing to unpack .../14-cuda-cufft-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-9-0.\n",
            "Preparing to unpack .../15-cuda-curand-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-0.\n",
            "Preparing to unpack .../16-cuda-curand-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-9-0.\n",
            "Preparing to unpack .../17-cuda-cusparse-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-0.\n",
            "Preparing to unpack .../18-cuda-cusparse-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-9-0.\n",
            "Preparing to unpack .../19-cuda-npp-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-0.\n",
            "Preparing to unpack .../20-cuda-npp-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-9-0.\n",
            "Preparing to unpack .../21-cuda-nvgraph-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-0.\n",
            "Preparing to unpack .../22-cuda-nvgraph-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-samples-9-0.\n",
            "Preparing to unpack .../23-cuda-samples-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-samples-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-documentation-9-0.\n",
            "Preparing to unpack .../24-cuda-documentation-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-0.\n",
            "Preparing to unpack .../25-cuda-libraries-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-9-0.\n",
            "Preparing to unpack .../26-cuda-nvml-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-9-0 (9.0.176-1) ...\n"
          ]
        }
      ],
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\n",
        "\n",
        "!ls  # Check if required cuda 9.0 amd64-deb file is downloaded\n",
        "\n",
        "!dpkg -i cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\n",
        "\n",
        "!ls /var/cuda-repo-9-0-local | grep .pub\n",
        "\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "!sudo apt-get install cuda-9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EDEz5WXBKhuD",
        "outputId": "fed6d189-99cc-4782-a5dc-4c909d17bae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python2.7 is already the newest version (2.7.17-1~18.04ubuntu1.6).\n",
            "python2.7 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 100 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install python2.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsxb6fNWJTu9"
      },
      "outputs": [],
      "source": [
        "!python2.7 -m pip install keras==2.2.0 numpy==1.14.0 tensorflow-gpu==1.8.0 h5py==2.8.0 ipdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiDBAva3UclD"
      },
      "source": [
        "# Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCsDJVHmHcLQ",
        "outputId": "22c1783a-021a-4c74-c5df-df71bca08b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "loading student model\n",
            "2022-01-02 15:09:30.939803: W tensorflow/core/framework/allocator.cc:101] Allocation of 411041792 exceeds 10% of system memory.\n",
            "/usr/local/lib/python2.7/dist-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "loading teacher model\n",
            "2022-01-02 15:09:34.487043: W tensorflow/core/framework/allocator.cc:101] Allocation of 411041792 exceeds 10% of system memory.\n",
            "building bottleneck model\n",
            "loading attacker\n",
            "Attacker loaded\n",
            "loading dataset\n",
            "filtering data\n",
            "baseline accuracy of student 0.938462\n",
            "X shape: (61, 224, 224, 3)\n",
            "Y shape: (61,)\n",
            "INFO: processing pair #0 source: 62, target: 33\n",
            "1 batches in total\n",
            "processing batch 0 at 2022-01-02 15:09:43.296832\n",
            "START:     Total loss: 2.1263E+02; perturb: 0.000000 (0.00% over, raw: 0.000000); sim: 212.627869\n",
            "ITER    0: Total loss: 2.1127E+02; perturb: 0.000000 (0.00% over, raw: 0.000002); sim: 211.269379\n",
            "ITER  200: Total loss: 1.1676E+02; perturb: 0.000000 (0.00% over, raw: 0.000963); sim: 116.757286\n",
            "ITER  400: Total loss: 1.0911E+02; perturb: 0.000000 (0.00% over, raw: 0.000976); sim: 109.108025\n",
            "ITER  600: Total loss: 1.0575E+02; perturb: 0.000000 (0.00% over, raw: 0.000983); sim: 105.751236\n",
            "ITER  800: Total loss: 1.0322E+02; perturb: 0.000002 (0.17% over, raw: 0.001002); sim: 103.196632\n",
            "ITER 1000: Total loss: 1.0183E+02; perturb: 0.000002 (0.25% over, raw: 0.001002); sim: 101.767273\n",
            "ITER 1200: Total loss: 1.0109E+02; perturb: 0.000000 (0.00% over, raw: 0.000995); sim: 101.094826\n",
            "ITER 1400: Total loss: 1.0106E+02; perturb: 0.000000 (0.00% over, raw: 0.000978); sim: 101.055229\n",
            "ITER 1600: Total loss: 9.9606E+01; perturb: 0.000000 (0.00% over, raw: 0.001000); sim: 99.605560\n",
            "ITER 1800: Total loss: 9.9093E+01; perturb: 0.000002 (0.22% over, raw: 0.001002); sim: 99.044914\n",
            "END:       Total loss: 9.9346E+01; perturb: 0.000000 (0.00% over, raw: 0.000984); sim: 99.345833\n",
            "Avg RMSD: 5.0506, STD RMSD: 0.0000\n",
            "attack cost 310.867815 s\n",
            "INFO: source: 62, target: 33, target_success: 1, img: 62-33.png\n",
            "INFO: processing pair #1 source: 22, target: 33\n",
            "1 batches in total\n",
            "processing batch 0 at 2022-01-02 15:14:54.262602\n",
            "START:     Total loss: 2.2007E+02; perturb: 0.000000 (0.00% over, raw: 0.000000); sim: 220.073532\n",
            "ITER    0: Total loss: 2.1902E+02; perturb: 0.000000 (0.00% over, raw: 0.000003); sim: 219.023636\n",
            "ITER  200: Total loss: 1.7494E+02; perturb: 0.000000 (0.00% over, raw: 0.000920); sim: 174.941772\n",
            "ITER  400: Total loss: 1.5633E+02; perturb: 0.000000 (0.00% over, raw: 0.000952); sim: 156.325455\n",
            "ITER  600: Total loss: 1.4742E+02; perturb: 0.000011 (1.05% over, raw: 0.001011); sim: 146.311539\n",
            "ITER  800: Total loss: 1.4298E+02; perturb: 0.000000 (0.00% over, raw: 0.000990); sim: 142.976105\n",
            "ITER 1000: Total loss: 1.4074E+02; perturb: 0.000000 (0.00% over, raw: 0.000998); sim: 140.737442\n",
            "ITER 1200: Total loss: 1.4029E+02; perturb: 0.000011 (1.14% over, raw: 0.001011); sim: 138.993790\n",
            "ITER 1400: Total loss: 1.3843E+02; perturb: 0.000000 (0.00% over, raw: 0.000999); sim: 138.427307\n",
            "ITER 1600: Total loss: 1.3893E+02; perturb: 0.000000 (0.00% over, raw: 0.000970); sim: 138.930267\n",
            "ITER 1800: Total loss: 1.3802E+02; perturb: 0.000011 (1.14% over, raw: 0.001011); sim: 136.716461\n",
            "END:       Total loss: 1.3784E+02; perturb: 0.000000 (0.00% over, raw: 0.000972); sim: 137.839676\n",
            "Avg RMSD: 5.7845, STD RMSD: 0.0000\n",
            "attack cost 309.943878 s\n",
            "INFO: source: 22, target: 33, target_success: 1, img: 22-33.png\n",
            "elapsed time 636.357326 s\n",
            "CPU times: user 4.46 s, sys: 641 ms, total: 5.11 s\n",
            "Wall time: 10min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python2.7 pubfig65_vggface_mimic_penalty_dssim.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui8tx26PUgQS"
      },
      "source": [
        "# Fingerprinting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5yqCk9oVXqJ",
        "outputId": "74f87d45-d223-449f-ee14-a42c2b04e331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "loading student model\n",
            "2022-01-01 14:44:25.652038: W tensorflow/core/framework/allocator.cc:101] Allocation of 411041792 exceeds 10% of system memory.\n",
            "2022-01-01 14:44:25.652596: W tensorflow/core/framework/allocator.cc:101] Allocation of 67108864 exceeds 10% of system memory.\n",
            "/usr/local/lib/python2.7/dist-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "loading teacher model\n",
            "2022-01-01 14:44:29.126593: W tensorflow/core/framework/allocator.cc:101] Allocation of 411041792 exceeds 10% of system memory.\n",
            "2022-01-01 14:44:29.126653: W tensorflow/core/framework/allocator.cc:101] Allocation of 67108864 exceeds 10% of system memory.\n",
            "2022-01-01 14:44:29.126698: W tensorflow/core/framework/allocator.cc:101] Allocation of 42958848 exceeds 10% of system memory.\n",
            "building bottleneck model\n",
            "loading attacker\n",
            "Attacker loaded\n",
            "building fingerprinting input\n",
            "1 batches in total\n",
            "processing batch 0 at 2022-01-01 14:44:31.452356\n",
            "START:     Total loss: 2.5936E+01; perturb: 0.000000 (0.00% over, raw: 0.000000); sim: 25.935564\n",
            "ITER    0: Total loss: 2.5698E+01; perturb: 0.000000 (0.00% over, raw: 0.000000); sim: 25.698139\n",
            "ITER  200: Total loss: 5.5973E+00; perturb: 0.000000 (0.00% over, raw: 0.005204); sim: 5.597337\n",
            "ITER  400: Total loss: 1.8699E+00; perturb: 0.000000 (0.00% over, raw: 0.010304); sim: 1.869945\n",
            "ITER  600: Total loss: 7.1206E-01; perturb: 0.000000 (0.00% over, raw: 0.013836); sim: 0.712059\n",
            "ITER  800: Total loss: 2.9325E-01; perturb: 0.000000 (0.00% over, raw: 0.016455); sim: 0.293254\n",
            "ITER 1000: Total loss: 1.2148E-01; perturb: 0.000000 (0.00% over, raw: 0.018224); sim: 0.121484\n",
            "ITER 1200: Total loss: 4.5743E-02; perturb: 0.000000 (0.00% over, raw: 0.019398); sim: 0.045743\n",
            "ITER 1400: Total loss: 1.0770E-02; perturb: 0.000000 (0.00% over, raw: 0.020166); sim: 0.010770\n",
            "ITER 1600: Total loss: 0.0000E+00; perturb: 0.000000 (0.00% over, raw: 0.020333); sim: 0.000000\n",
            "ITER 1800: Total loss: 0.0000E+00; perturb: 0.000000 (0.00% over, raw: 0.020333); sim: 0.000000\n",
            "END:       Total loss: 0.0000E+00; perturb: 0.000000 (0.00% over, raw: 0.020333); sim: 0.000000\n",
            "Avg RMSD: 10.4839, STD RMSD: 0.0000\n",
            "attack cost 213.969972 s\n",
            "testing fingerprint image on student\n",
            "INFO: avg_gini: 0.003538, avg_max_conf: 0.015828\n",
            "elapsed time 222.465369 s\n",
            "CPU times: user 1.51 s, sys: 267 ms, total: 1.78 s\n",
            "Wall time: 3min 44s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python2.7 pubfig65_fingerprint_vggface.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_jrwjz6KQFI",
        "outputId": "4b99eee8-45d4-4077-900a-024514c5d37d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "loading student model\n",
            "2022-01-01 15:05:00.018879: W tensorflow/core/framework/allocator.cc:101] Allocation of 411041792 exceeds 10% of system memory.\n",
            "/usr/local/lib/python2.7/dist-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "loading teacher model\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 57s 0us/step\n",
            "553476096/553467096 [==============================] - 57s 0us/step\n",
            "2022-01-01 15:05:59.252058: W tensorflow/core/framework/allocator.cc:101] Allocation of 411041792 exceeds 10% of system memory.\n",
            "building bottleneck model\n",
            "loading attacker\n",
            "Attacker loaded\n",
            "building fingerprinting input\n",
            "1 batches in total\n",
            "processing batch 0 at 2022-01-01 15:06:01.498691\n",
            "START:     Total loss: 6.4014E+01; perturb: 0.000000 (0.00% over, raw: -0.000000); sim: 64.014488\n",
            "ITER    0: Total loss: 6.3486E+01; perturb: 0.000000 (0.00% over, raw: -0.000000); sim: 63.486332\n",
            "ITER  200: Total loss: 2.0770E+01; perturb: 0.000000 (0.00% over, raw: 0.002712); sim: 20.770098\n",
            "ITER  400: Total loss: 1.3369E+01; perturb: 0.000000 (0.00% over, raw: 0.006019); sim: 13.369108\n",
            "ITER  600: Total loss: 9.5296E+00; perturb: 0.000000 (0.00% over, raw: 0.009691); sim: 9.529629\n",
            "ITER  800: Total loss: 7.5022E+00; perturb: 0.000000 (0.00% over, raw: 0.013284); sim: 7.502194\n",
            "ITER 1000: Total loss: 6.2279E+00; perturb: 0.000000 (0.00% over, raw: 0.016837); sim: 6.227852\n",
            "ITER 1200: Total loss: 4.9114E+00; perturb: 0.000000 (0.00% over, raw: 0.020441); sim: 4.911439\n",
            "ITER 1400: Total loss: 3.8458E+00; perturb: 0.000000 (0.00% over, raw: 0.023867); sim: 3.845803\n",
            "ITER 1600: Total loss: 3.0114E+00; perturb: 0.000000 (0.00% over, raw: 0.027031); sim: 3.011397\n",
            "ITER 1800: Total loss: 2.0910E+00; perturb: 0.000000 (0.00% over, raw: 0.030262); sim: 2.091019\n",
            "END:       Total loss: 1.1185E+00; perturb: 0.000000 (0.00% over, raw: 0.033198); sim: 1.118482\n",
            "Avg RMSD: 15.5820, STD RMSD: 0.0000\n",
            "attack cost 212.535908 s\n",
            "testing fingerprint image on student\n",
            "INFO: avg_gini: 0.500964, avg_max_conf: 0.097207\n",
            "elapsed time 276.491050 s\n",
            "CPU times: user 2.52 s, sys: 454 ms, total: 2.98 s\n",
            "Wall time: 4min 38s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python2.7 pubfig65_fingerprint_vgg16.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YJvdYu51ChW"
      },
      "source": [
        "# Patch neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57PQk5G4KyBZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!python2.7 pubfig65_patch_neuron_distance.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypqQ9JyOUQv4"
      },
      "source": [
        "# Extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzQgfkn_USx_"
      },
      "outputs": [],
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1JibtwaJ0PFynllvMVzqJBOJpMZt5J5kL\" -O \"models/iris_vgg16_trans.h5\"\n",
        "!gdown \"https://drive.google.com/uc?id=1-b4Swcr0XDZ2Car9Ed9E9-9Vgciqa87r\" -O \"models/gtsrb_vgg16_trans.h5\"\n",
        "!gdown \"https://drive.google.com/uc?id=1BR3g0Sq5WoqcaJe5GRvawfxDKmLoSLW7\" -O \"models/flower_resnet50_trans.h5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTs8PFSK2Qzb"
      },
      "source": [
        "# Experiment on Food classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74i9pLWnXbDj",
        "outputId": "93d1d27b-6c35-4f8b-fb44-057abd34eb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QlwYG5HEU3SIG1FMVp_7VPZ1gyiGNwT4\n",
            "To: /content/translearn/food_models/extractor__tl_model_v1.weights.best.hdf5\n",
            "100% 1.34G/1.34G [00:29<00:00, 46.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-9VarST9tJkHFVbstK7UlbxzntfMPJP2\n",
            "To: /content/translearn/food_models/fine_tuned__tl_model_v1.weights.best.hdf5\n",
            "100% 1.36G/1.36G [00:28<00:00, 47.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qvP9MEyDLacUSBGOogTpN8UCS8OZav04\n",
            "To: /content/translearn/food_models/vgg16.h5\n",
            "100% 554M/554M [00:09<00:00, 56.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./food_models/\n",
        "!gdown \"https://drive.google.com/uc?id=1QlwYG5HEU3SIG1FMVp_7VPZ1gyiGNwT4\" -O \"food_models/extractor__tl_model_v1.weights.best.hdf5\"\n",
        "!gdown \"https://drive.google.com/uc?id=1-9VarST9tJkHFVbstK7UlbxzntfMPJP2\" -O \"food_models/fine_tuned__tl_model_v1.weights.best.hdf5\"\n",
        "!gdown \"https://drive.google.com/uc?id=1qvP9MEyDLacUSBGOogTpN8UCS8OZav04\" -O \"food_models/vgg16.h5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6_amPFaYPAO"
      },
      "source": [
        "Download and load food dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "smB3LH55YNVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2421ea27-b355-491f-b010-71e1e7ce286e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-05 14:43:01--  http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz [following]\n",
            "--2022-01-05 14:43:01--  https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4996278331 (4.7G) [application/x-gzip]\n",
            "Saving to: ‘food-101.tar.gz’\n",
            "\n",
            "food-101.tar.gz     100%[===================>]   4.65G  30.7MB/s    in 2m 42s  \n",
            "\n",
            "2022-01-05 14:45:44 (29.4 MB/s) - ‘food-101.tar.gz’ saved [4996278331/4996278331]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "!tar xzf food-101.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_QexlalTgpA"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOKWjlRfIZCl"
      },
      "source": [
        "\\################################## Start test \\##################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect model"
      ],
      "metadata": {
        "id": "0NVMsS7sWkoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlxGzo98A8t1"
      },
      "outputs": [],
      "source": [
        "food_student_model = load_model(\"food_models/extractor__tl_model_v1.weights.best.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIAHXIFGBIM1",
        "outputId": "f15d7000-7e36-435b-c999-74e86390a1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<keras.engine.input_layer.InputLayer object at 0x7f3addc27ed0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3ad92da690>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3ad92da790>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3add555f50>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3add497d50>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64c22c90>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3ad9288310>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3add482890>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3add482610>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64b29d90>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64b4e450>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64b4b890>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64b34290>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64b35b10>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64b3b590>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64b3f710>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64e70210>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64dea150>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64b1ebd0>,\n",
            " <keras.layers.core.flatten.Flatten object at 0x7f3a64b15d90>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a64b1b710>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a6870d710>,\n",
            " <keras.layers.core.dropout.Dropout object at 0x7f3a64b8aed0>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a64b8aa50>]\n",
            "24\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(food_student_model.layers)\n",
        "pprint(len(food_student_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR0aOa8rIfE3",
        "outputId": "c27527b5-f403-4613-b19c-15cfb58c573c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "model=VGG16(include_top=True , weights=\"imagenet\")\n",
        "model.save(\"vgg16.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS1L8cuOLruf",
        "outputId": "a1b738fc-b8ba-492a-eec0-a6512a12472d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after 'vgg16.h5'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ],
      "source": [
        "!cp vgg16.h5 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s8ZMAroKSSs",
        "outputId": "8d218903-912d-47a9-b84d-464c7b341ee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<keras.engine.input_layer.InputLayer object at 0x7f3a64531410>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64531990>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64531dd0>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a645207d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64538110>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64541250>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64538910>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a645456d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a6454f4d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a61296690>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a6454f350>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a6129a0d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a6129bc90>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a612a0310>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a6129a110>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a612ab690>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a612b3410>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a612abf90>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a612bae50>,\n",
            " <keras.layers.core.flatten.Flatten object at 0x7f3a612c15d0>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a612cc250>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a612c3210>,\n",
            " <keras.layers.core.dense.Dense object at 0x7f3a612ba2d0>]\n",
            "23\n"
          ]
        }
      ],
      "source": [
        "pprint(model.layers)\n",
        "pprint(len(model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otVYlOJKR1WT",
        "outputId": "ee1a1dd6-07dd-4045-d8df-d38d8a4e479d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "[<keras.engine.input_layer.InputLayer object at 0x7f3a610a1550>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64c2a3d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a610a92d0>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64bd8350>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a61087490>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a60dab3d0>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64cca290>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64bbcfd0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a60f54890>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64c2ad10>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a60c9a390>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a6069d650>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a606bb0d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a60a8fd50>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a607400d0>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a60a97e50>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a606f5190>,\n",
            " <keras.layers.convolutional.Conv2D object at 0x7f3a64520a50>,\n",
            " <keras.layers.pooling.MaxPooling2D object at 0x7f3a64c3e350>]\n",
            "19\n"
          ]
        }
      ],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "conv_base = VGG16(include_top=False,\n",
        "                  weights='imagenet', \n",
        "                  input_shape=input_shape)\n",
        "pprint(conv_base.layers)\n",
        "pprint(len(conv_base.layers))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare dataset"
      ],
      "metadata": {
        "id": "c1oiqjX3feYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move data from images to images/train or images/test: \n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def split_dataset(root_food_path):\n",
        "    \"\"\"Takes in the path for food-101 directory and creates train/test dirs of images\"\"\"\n",
        "    data_paths = {\n",
        "        'train': root_food_path/'meta/train.json',\n",
        "        'test': root_food_path/'meta/test.json'\n",
        "    }\n",
        "    for data_type, meta_path in data_paths.items():\n",
        "        # Make the train/test dirs\n",
        "        os.makedirs(root_food_path/data_type, exist_ok=True)\n",
        "        \n",
        "        # Read the meta files. \n",
        "        # These are loaded as a dict of food names with a list of image paths\n",
        "        # E.g. {\"<food_name>\": [\"<food_name>/<image_num>\", ...], ...}\n",
        "        food_images = json.load(open(meta_path, 'r'))\n",
        "        \n",
        "        for food_name, image_paths in food_images.items():\n",
        "            # Make food dir in train/test dir\n",
        "            os.makedirs(root_food_path/data_type/food_name, exist_ok=True)\n",
        "            \n",
        "            # Move images from food-101/images to food-101/train (or test)\n",
        "            for image_path in image_paths:\n",
        "                image_path = image_path + '.jpg'\n",
        "                shutil.move(root_food_path/'images'/image_path, root_food_path/data_type/image_path)"
      ],
      "metadata": {
        "id": "KELGW2RLhaZ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Gb31IRAUfhSi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_generator = ImageDataGenerator(rotation_range=90, \n",
        "                                     brightness_range=[0.1, 0.7],\n",
        "                                     width_shift_range=0.5, \n",
        "                                     height_shift_range=0.5,\n",
        "                                     horizontal_flip=True, \n",
        "                                     vertical_flip=True,\n",
        "                                     validation_split=0.15,\n",
        "                                     preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing"
      ],
      "metadata": {
        "id": "hFgljC8hg_pu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download_dir = Path('/content/')\n",
        "download_dir = Path('.')\n",
        "\n",
        "split_dataset(download_dir/'food-101')"
      ],
      "metadata": {
        "id": "ZDooMd_LhYvt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = download_dir/'food-101/train'\n",
        "test_data_dir = download_dir/'food-101/test'\n",
        "\n",
        "class_subset = sorted(os.listdir(download_dir/'food-101/images'))[:10] # Using only the first 10 classes"
      ],
      "metadata": {
        "id": "Kx03CE4MhdnA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='training',\n",
        "                                               batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=True,\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8BQHSCphjHg",
        "outputId": "7df13db9-a3c2-45f5-d1f7-48a0905787ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6380 images belonging to 10 classes.\n",
            "Found 1120 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = next(testgen)"
      ],
      "metadata": {
        "id": "CFMO4XT8h_Uu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xDGpdtHt1ck",
        "outputId": "817efa9e-9bf6-4d5a-e750-fc8db2f19298"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2004"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(f.get(\"X_test\")[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK_Voepsw1Ml",
        "outputId": "b303ae3d-2e0f-47dd-8cbf-4f65f3acaee4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163.0399859162415"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(tmp[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjJC4jqXiEtQ",
        "outputId": "66577a19-5105-4a1e-ac3c-76bfed8e5363"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.416185"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = testgen.labels"
      ],
      "metadata": {
        "id": "lx9f3CZmmkXo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "\n",
        "image_array = f.get(\"X_test\")[0]\n",
        "im = Image.fromarray(np.uint8(image_array))\n",
        "im.save(f\"sample_imagenet_test_0.png\")"
      ],
      "metadata": {
        "id": "Y0XdKzmWxMY8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DVxc2dknlw2",
        "outputId": "49f9cdfa-895c-490f-fa46-c6b916246f9a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_food():\n",
        "  \"\"\"Specific function for loading food dataset\"\"\"\n"
      ],
      "metadata": {
        "id": "GxnSPdtku0Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check model classification"
      ],
      "metadata": {
        "id": "_Yy020a9WoB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_student_model = load_model(\"food_models/extractor__tl_model_v1.weights.best.hdf5\")"
      ],
      "metadata": {
        "id": "dw3nxTc_WrbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qDVziCdIcV3"
      },
      "source": [
        "\\################################## End test \\##################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ6m_3JKTkNs"
      },
      "source": [
        "## Conducting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJiQ9ZiBYTrA"
      },
      "outputs": [],
      "source": [
        "# Move data from images to images/train or images/test: \n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def split_dataset(root_food_path):\n",
        "    \"\"\"Takes in the path for food-101 directory and creates train/test dirs of images\"\"\"\n",
        "    data_paths = {\n",
        "        'train': root_food_path/'meta/train.json',\n",
        "        'test': root_food_path/'meta/test.json'\n",
        "    }\n",
        "    for data_type, meta_path in data_paths.items():\n",
        "        # Make the train/test dirs\n",
        "        os.makedirs(root_food_path/data_type, exist_ok=True)\n",
        "        \n",
        "        # Read the meta files. \n",
        "        # These are loaded as a dict of food names with a list of image paths\n",
        "        # E.g. {\"<food_name>\": [\"<food_name>/<image_num>\", ...], ...}\n",
        "        food_images = json.load(open(meta_path, 'r'))\n",
        "        \n",
        "        for food_name, image_paths in food_images.items():\n",
        "            # Make food dir in train/test dir\n",
        "            os.makedirs(root_food_path/data_type/food_name, exist_ok=True)\n",
        "            \n",
        "            # Move images from food-101/images to food-101/train (or test)\n",
        "            for image_path in image_paths:\n",
        "                image_path = image_path + '.jpg'\n",
        "                shutil.move(root_food_path/'images'/image_path, root_food_path/data_type/image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fnRf3jLYacq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "download_dir = Path('/content/translearn/')\n",
        "\n",
        "split_dataset(download_dir/'food-101')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWgg26lC8eeG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "class_subset = sorted(os.listdir(download_dir/'food-101/images'))[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGbcBsxP8hec",
        "outputId": "d0a0cc5d-a7f8-4362-935e-7575c0773d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 370 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1/255.,              # normalize pixel values between 0-1\n",
        "    brightness_range=[0.1, 0.7], # specify the range in which to decrease/increase brightness\n",
        "    width_shift_range=0.5,       # shift the width of the image 50%\n",
        "    rotation_range=90,           # random rotation by 90 degrees\n",
        "    horizontal_flip=True,        # 180 degree flip horizontally\n",
        "    vertical_flip=True,          # 180 degree flip vertically\n",
        "    validation_split=0.15        # 15% of the data will be used for validation at end of each epoch\n",
        ")\n",
        "\n",
        "# test for integration with adversarial model\n",
        "testgen = train_generator.flow_from_directory(\n",
        "    download_dir/'food-101/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    classes=class_subset,\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhmAIJBlVIDG"
      },
      "outputs": [],
      "source": [
        "data_list = []\n",
        "batch_index = 0\n",
        "\n",
        "while batch_index <= testgen.batch_index:\n",
        "    data = testgen.next()\n",
        "    data_list.append(data[0])\n",
        "    batch_index = batch_index + 1\n",
        "\n",
        "# now, data_array is the numeric data of whole images\n",
        "data_array = np.asarray(data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs5Wf_GpYYrL"
      },
      "source": [
        "Prepare model for attacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0C6ktzG2g-K"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "food_classifier_path = Path(\"/content/translearn/food_models/\")\n",
        "# Deep-layer feature extractor\n",
        "dlfe_model = food_clssifier_path/\"extractor__tl_model_v1.weights.best.hdf5\"\n",
        "\n",
        "# Mid-layer feature extractor (K=N-3)\n",
        "mlfe_model = food_clssifier_path/\"fine_tuned__tl_model_v1.weights.best.hdf5\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "[NT522]_With_Great_Training_Comes_Great_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}